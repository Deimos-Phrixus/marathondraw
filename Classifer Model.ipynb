{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filenames = os.listdir(\"dataset/\")\n",
    "categories = np.load(\"dataset/categories.npz\")['categories']\n",
    "X_train_set = []\n",
    "Y_train_set = []\n",
    "X_test_set = []\n",
    "Y_test_set = []\n",
    "for each in dataset_filenames:\n",
    "    if 'test' in each:\n",
    "        test_data = np.load(\"dataset/\"+each)\n",
    "        X_test_set.append(test_data['X_test'])\n",
    "        Y_test_set.append(test_data['Y_test'])\n",
    "    elif 'train' in each:\n",
    "        train_data = np.load(\"dataset/\"+each)\n",
    "        X_train_set.append(train_data['X_train'])\n",
    "        Y_train_set.append(train_data['Y_train'])\n",
    "X_train = np.concatenate(X_train_set)\n",
    "Y_train = np.concatenate(Y_train_set)\n",
    "X_test = np.concatenate(X_test_set)\n",
    "Y_test = np.concatenate(Y_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 784) (100000, 10)\n",
      "(20000, 784) (20000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "import os\n",
    "plaidml.keras.install_backend()\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'plaidml.keras.backend' from 'C:\\\\Users\\\\rhemo\\\\Anaconda3\\\\lib\\\\site-packages\\\\plaidml\\\\keras\\\\backend.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    \n",
    "    def __init__(self, model=None):\n",
    "        self.model = model\n",
    "        \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def create_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dropout(0.2, input_shape=(28,28,1)))\n",
    "        model.add(Conv2D(32,kernel_size=7,padding='same',activation='relu'))\n",
    "        model.add(MaxPool2D())\n",
    "        model.add(Conv2D(64,kernel_size=3,padding='same',activation='relu'))\n",
    "        model.add(MaxPool2D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \n",
    "    def fit_model(self, X_train, Y_train, X_test, Y_test, epochs=5, batch_size=256):\n",
    "        print(\"Starting model training\")\n",
    "        print(\"Loss values before training with test data:\", self.model.evaluate(X_test, Y_test))\n",
    "        self.model.fit(x=X_train, y=Y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=1)\n",
    "        print(\"Loss values after training with test data:\", self.model.evaluate(X_test, Y_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 28, 28, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 28, 28, 1) (20000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_gfx902.0\"\n"
     ]
    }
   ],
   "source": [
    "classifer = Classifier(Classifier.create_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training\n",
      "20000/20000 [==============================] - 7s 355us/step\n",
      "Loss values before training with test data: [0.4497741224765778, 0.8882]\n",
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "90000/90000 [==============================] - 37s 408us/step - loss: 0.1224 - acc: 0.9576 - val_loss: 0.4834 - val_acc: 0.8822\n",
      "Epoch 2/60\n",
      "90000/90000 [==============================] - 35s 386us/step - loss: 0.1215 - acc: 0.9580 - val_loss: 0.4980 - val_acc: 0.8798\n",
      "Epoch 3/60\n",
      "90000/90000 [==============================] - 32s 360us/step - loss: 0.1158 - acc: 0.9599 - val_loss: 0.4858 - val_acc: 0.8819\n",
      "Epoch 4/60\n",
      "90000/90000 [==============================] - 32s 353us/step - loss: 0.1106 - acc: 0.9615 - val_loss: 0.5009 - val_acc: 0.8846\n",
      "Epoch 5/60\n",
      "90000/90000 [==============================] - 32s 360us/step - loss: 0.1093 - acc: 0.9624 - val_loss: 0.5074 - val_acc: 0.8875\n",
      "Epoch 6/60\n",
      "90000/90000 [==============================] - 32s 354us/step - loss: 0.1045 - acc: 0.9642 - val_loss: 0.5026 - val_acc: 0.8829\n",
      "Epoch 7/60\n",
      "90000/90000 [==============================] - 32s 359us/step - loss: 0.1059 - acc: 0.9638 - val_loss: 0.5001 - val_acc: 0.8819\n",
      "Epoch 8/60\n",
      "90000/90000 [==============================] - 34s 382us/step - loss: 0.0996 - acc: 0.9656 - val_loss: 0.5201 - val_acc: 0.8743\n",
      "Epoch 9/60\n",
      "90000/90000 [==============================] - 36s 402us/step - loss: 0.1032 - acc: 0.9643 - val_loss: 0.5168 - val_acc: 0.8788\n",
      "Epoch 10/60\n",
      "90000/90000 [==============================] - 38s 425us/step - loss: 0.0963 - acc: 0.9672 - val_loss: 0.5285 - val_acc: 0.8808\n",
      "Epoch 11/60\n",
      "90000/90000 [==============================] - 33s 363us/step - loss: 0.0951 - acc: 0.9672 - val_loss: 0.5250 - val_acc: 0.8819\n",
      "Epoch 12/60\n",
      "90000/90000 [==============================] - 33s 369us/step - loss: 0.0960 - acc: 0.9662 - val_loss: 0.5396 - val_acc: 0.8783\n",
      "Epoch 13/60\n",
      "90000/90000 [==============================] - 32s 360us/step - loss: 0.0917 - acc: 0.9684 - val_loss: 0.5344 - val_acc: 0.8832\n",
      "Epoch 14/60\n",
      "90000/90000 [==============================] - 34s 378us/step - loss: 0.0889 - acc: 0.9695 - val_loss: 0.5509 - val_acc: 0.8796\n",
      "Epoch 15/60\n",
      "90000/90000 [==============================] - 33s 362us/step - loss: 0.0887 - acc: 0.9697 - val_loss: 0.5353 - val_acc: 0.8804\n",
      "Epoch 16/60\n",
      "90000/90000 [==============================] - 32s 353us/step - loss: 0.0881 - acc: 0.9696 - val_loss: 0.5531 - val_acc: 0.8811\n",
      "Epoch 17/60\n",
      "90000/90000 [==============================] - 32s 357us/step - loss: 0.0832 - acc: 0.9710 - val_loss: 0.5588 - val_acc: 0.8856\n",
      "Epoch 18/60\n",
      "90000/90000 [==============================] - 32s 353us/step - loss: 0.0829 - acc: 0.9716 - val_loss: 0.5721 - val_acc: 0.8798\n",
      "Epoch 19/60\n",
      "90000/90000 [==============================] - 39s 431us/step - loss: 0.0842 - acc: 0.9712 - val_loss: 0.5720 - val_acc: 0.8824\n",
      "Epoch 20/60\n",
      "90000/90000 [==============================] - 37s 410us/step - loss: 0.0813 - acc: 0.9714 - val_loss: 0.5710 - val_acc: 0.8814\n",
      "Epoch 21/60\n",
      "90000/90000 [==============================] - 34s 377us/step - loss: 0.0804 - acc: 0.9720 - val_loss: 0.5871 - val_acc: 0.8718\n",
      "Epoch 22/60\n",
      "90000/90000 [==============================] - 32s 360us/step - loss: 0.0745 - acc: 0.9737 - val_loss: 0.5676 - val_acc: 0.8816\n",
      "Epoch 23/60\n",
      "90000/90000 [==============================] - 34s 374us/step - loss: 0.0759 - acc: 0.9740 - val_loss: 0.5677 - val_acc: 0.8816\n",
      "Epoch 24/60\n",
      "90000/90000 [==============================] - 34s 376us/step - loss: 0.0753 - acc: 0.9736 - val_loss: 0.5853 - val_acc: 0.8827\n",
      "Epoch 25/60\n",
      "90000/90000 [==============================] - 33s 363us/step - loss: 0.0747 - acc: 0.9745 - val_loss: 0.5953 - val_acc: 0.8849\n",
      "Epoch 26/60\n",
      "90000/90000 [==============================] - 34s 382us/step - loss: 0.0723 - acc: 0.9756 - val_loss: 0.5872 - val_acc: 0.8856\n",
      "Epoch 27/60\n",
      "90000/90000 [==============================] - 32s 358us/step - loss: 0.0724 - acc: 0.9750 - val_loss: 0.6033 - val_acc: 0.8815\n",
      "Epoch 28/60\n",
      "90000/90000 [==============================] - 41s 454us/step - loss: 0.0709 - acc: 0.9759 - val_loss: 0.5817 - val_acc: 0.8830\n",
      "Epoch 29/60\n",
      "90000/90000 [==============================] - 33s 372us/step - loss: 0.0695 - acc: 0.9761 - val_loss: 0.5833 - val_acc: 0.8765\n",
      "Epoch 30/60\n",
      "90000/90000 [==============================] - 35s 389us/step - loss: 0.0690 - acc: 0.9769 - val_loss: 0.6276 - val_acc: 0.8832\n",
      "Epoch 31/60\n",
      "90000/90000 [==============================] - 33s 364us/step - loss: 0.0711 - acc: 0.9756 - val_loss: 0.5979 - val_acc: 0.8816\n",
      "Epoch 32/60\n",
      "90000/90000 [==============================] - 33s 364us/step - loss: 0.0673 - acc: 0.9765 - val_loss: 0.5999 - val_acc: 0.8811\n",
      "Epoch 33/60\n",
      "90000/90000 [==============================] - 34s 379us/step - loss: 0.0668 - acc: 0.9775 - val_loss: 0.6353 - val_acc: 0.8840\n",
      "Epoch 34/60\n",
      "90000/90000 [==============================] - 37s 406us/step - loss: 0.0635 - acc: 0.9782 - val_loss: 0.6461 - val_acc: 0.8806\n",
      "Epoch 35/60\n",
      "90000/90000 [==============================] - 35s 391us/step - loss: 0.0661 - acc: 0.9772 - val_loss: 0.6274 - val_acc: 0.8779\n",
      "Epoch 36/60\n",
      "90000/90000 [==============================] - 37s 411us/step - loss: 0.0641 - acc: 0.9775 - val_loss: 0.6146 - val_acc: 0.8851\n",
      "Epoch 37/60\n",
      "90000/90000 [==============================] - 33s 365us/step - loss: 0.0632 - acc: 0.9781 - val_loss: 0.6319 - val_acc: 0.8767\n",
      "Epoch 38/60\n",
      "90000/90000 [==============================] - 32s 355us/step - loss: 0.0638 - acc: 0.9783 - val_loss: 0.6258 - val_acc: 0.8792\n",
      "Epoch 39/60\n",
      "90000/90000 [==============================] - 33s 362us/step - loss: 0.0612 - acc: 0.9792 - val_loss: 0.6249 - val_acc: 0.8790\n",
      "Epoch 40/60\n",
      "90000/90000 [==============================] - 33s 366us/step - loss: 0.0630 - acc: 0.9782 - val_loss: 0.6471 - val_acc: 0.8802\n",
      "Epoch 41/60\n",
      "90000/90000 [==============================] - 35s 387us/step - loss: 0.0589 - acc: 0.9796 - val_loss: 0.6362 - val_acc: 0.8793\n",
      "Epoch 42/60\n",
      "90000/90000 [==============================] - 33s 372us/step - loss: 0.0611 - acc: 0.9789 - val_loss: 0.6364 - val_acc: 0.8808\n",
      "Epoch 43/60\n",
      "90000/90000 [==============================] - 37s 412us/step - loss: 0.0577 - acc: 0.9800 - val_loss: 0.6303 - val_acc: 0.8731\n",
      "Epoch 44/60\n",
      "90000/90000 [==============================] - 38s 422us/step - loss: 0.0589 - acc: 0.9794 - val_loss: 0.6493 - val_acc: 0.8797\n",
      "Epoch 45/60\n",
      "90000/90000 [==============================] - 35s 393us/step - loss: 0.0584 - acc: 0.9797 - val_loss: 0.6720 - val_acc: 0.8815\n",
      "Epoch 46/60\n",
      "90000/90000 [==============================] - 32s 360us/step - loss: 0.0571 - acc: 0.9803 - val_loss: 0.6393 - val_acc: 0.8758\n",
      "Epoch 47/60\n",
      "90000/90000 [==============================] - 31s 346us/step - loss: 0.0566 - acc: 0.9813 - val_loss: 0.6602 - val_acc: 0.8778\n",
      "Epoch 48/60\n",
      "90000/90000 [==============================] - 33s 367us/step - loss: 0.0576 - acc: 0.9802 - val_loss: 0.6370 - val_acc: 0.8785\n",
      "Epoch 49/60\n",
      "90000/90000 [==============================] - 33s 370us/step - loss: 0.0577 - acc: 0.9799 - val_loss: 0.6659 - val_acc: 0.8816\n",
      "Epoch 50/60\n",
      "90000/90000 [==============================] - 33s 363us/step - loss: 0.0541 - acc: 0.9817 - val_loss: 0.6539 - val_acc: 0.8774\n",
      "Epoch 51/60\n",
      "90000/90000 [==============================] - 33s 362us/step - loss: 0.0554 - acc: 0.9807 - val_loss: 0.6580 - val_acc: 0.8786\n",
      "Epoch 52/60\n",
      "90000/90000 [==============================] - 34s 381us/step - loss: 0.0566 - acc: 0.9804 - val_loss: 0.6674 - val_acc: 0.8809\n",
      "Epoch 53/60\n",
      "90000/90000 [==============================] - 34s 375us/step - loss: 0.0545 - acc: 0.9814 - val_loss: 0.6512 - val_acc: 0.8780\n",
      "Epoch 54/60\n",
      "90000/90000 [==============================] - 39s 431us/step - loss: 0.0541 - acc: 0.9816 - val_loss: 0.6513 - val_acc: 0.8810\n",
      "Epoch 55/60\n",
      "90000/90000 [==============================] - 33s 361us/step - loss: 0.0529 - acc: 0.9820 - val_loss: 0.6710 - val_acc: 0.8831\n",
      "Epoch 56/60\n",
      "90000/90000 [==============================] - 34s 375us/step - loss: 0.0516 - acc: 0.9819 - val_loss: 0.6806 - val_acc: 0.8756\n",
      "Epoch 57/60\n",
      "90000/90000 [==============================] - 32s 358us/step - loss: 0.0527 - acc: 0.9821 - val_loss: 0.6910 - val_acc: 0.8744\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000/90000 [==============================] - 33s 367us/step - loss: 0.0538 - acc: 0.9816 - val_loss: 0.6650 - val_acc: 0.8779\n",
      "Epoch 59/60\n",
      "90000/90000 [==============================] - 34s 375us/step - loss: 0.0514 - acc: 0.9821 - val_loss: 0.6713 - val_acc: 0.8763\n",
      "Epoch 60/60\n",
      "90000/90000 [==============================] - 35s 388us/step - loss: 0.0526 - acc: 0.9821 - val_loss: 0.6726 - val_acc: 0.8790\n",
      "20000/20000 [==============================] - 8s 386us/step\n",
      "Loss values after training with test data: [0.6468242520451546, 0.8829]\n"
     ]
    }
   ],
   "source": [
    "classifer.fit_model(X_train, Y_train, X_test, Y_test, batch_size=512, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classifer.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 7s 345us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6468242520451546, 0.8829]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.ipynb_checkpoints',\n",
       " 'backend',\n",
       " 'categories.txt',\n",
       " 'Classifer Model.ipynb',\n",
       " 'data',\n",
       " 'dataset',\n",
       " 'frontend',\n",
       " 'modelv1.h5',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'Understanding & Preparing Data.ipynb']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelv1 = load_model('modelv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 7s 359us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4497741224765778, 0.8882]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelv1.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
